{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615792e6",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "import openai\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e871d-dbf8-4cb1-897d-bdaef21b170d",
   "metadata": {},
   "source": [
    "### Set LLM with Ollama (Tinyllama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5843a4c5-e11f-4c32-b446-2aec529a5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"tinyllama:latest\", request_timeout=120.0)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a010330-bc6a-4e1c-8605-16afe8200585",
   "metadata": {},
   "source": [
    "### Set embedding model (Bge-base-en-v1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6be1f9-b33d-400a-a471-eeeeb35c0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2e828-7a94-463f-89b0-2d75521319a7",
   "metadata": {},
   "source": [
    "### Define data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280f6ae9-b082-4a6d-8705-12849fb1a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = SimpleDirectoryReader(\n",
    "    r\"/Users/arthursarazin/Documents/RAGdesign/data\"\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8aa03e",
   "metadata": {},
   "source": [
    "### Utilitary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0666d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(doc):\n",
    "    # This function will be called for each document\n",
    "    print(f\"Processing document: {doc.doc_id}\")\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94eacca-42e3-4140-a620-c199f3578e6e",
   "metadata": {},
   "source": [
    "# Construct stores and indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52227d",
   "metadata": {},
   "source": [
    "## Vector \n",
    "\n",
    "Data will be transformed and stored as vectors using the embedding model. The vector store will be used to retrieve relevant documents based on the query. A vector in this context is a numerical representation of the text data, which allows for efficient similarity search. A vector index will be created to facilitate this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a821e-abd8-4cb4-b2dc-98163aa332df",
   "metadata": {},
   "source": [
    "### Construct vector store and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fee7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents = simple_glossary,\n",
    "    show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fec3c",
   "metadata": {},
   "source": [
    "### Save  index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c8c116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.set_index_id(\"vector_index\")\n",
    "vector_index.storage_context.persist(\"vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3e86b",
   "metadata": {},
   "source": [
    "## Property Graph\n",
    "\n",
    "Data will be transformed into a property graph format. A property graph is a data structure that consists of nodes (entities) and edges (relationships) with properties. This format allows for complex queries and relationships to be represented and queried efficiently. The property graph store will be used to retrieve relevant documents based on the query. A property graph index will be created to facilitate this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b541a",
   "metadata": {},
   "source": [
    "### Define a knowledge graph extractor for property graph structure\n",
    "\n",
    "To define what entities and relation types to extract from the text, we will use a knowledge graph extractor. This extractor will identify and extract relevant entities and relationships from the text data, which will then be used to construct the property graph store and index. \n",
    "\n",
    "In this blueprint, the entities are defined by the title of Obsidian marksdown files, and the relations are defined by the links between these files. The extractor will identify these entities and relationships and create a property graph structure that can be queried efficiently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cffe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_and_title(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "        if content.startswith(\"---\"):\n",
    "            try:\n",
    "                parts = content.split(\"---\", 2)\n",
    "                if len(parts) > 2:\n",
    "                    yaml_block = parts[1]\n",
    "                    metadata = yaml.safe_load(yaml_block)\n",
    "                    return os.path.basename(file_path).replace(\".md\", \"\"), metadata\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction des métadonnées de {file_path}: {e}\")\n",
    "                return None, None\n",
    "        return os.path.basename(file_path).replace(\".md\", \"\"), None\n",
    "\n",
    "def process_obsidian_notes(directory):\n",
    "    entities = []\n",
    "    relations = []\n",
    "    contents = []\n",
    "    relation_types = {}\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                title, metadata = extract_metadata_and_title(file_path)\n",
    "                \n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    if content.startswith(\"---\"):\n",
    "                        parts = content.split(\"---\", 2)\n",
    "                        entity_content = parts[2].strip() if len(parts) > 2 else \"\"\n",
    "                    else:\n",
    "                        entity_content = content.strip()\n",
    "                \n",
    "                if title:\n",
    "                    entities.append({\"name\": title})\n",
    "                    contents.append({\"content\": entity_content})\n",
    "                    \n",
    "                    if metadata:\n",
    "                        for key, value in metadata.items():\n",
    "                            relations.append({\n",
    "                                \"type\": key,\n",
    "                                \"source\": title,\n",
    "                                \"target\": value,\n",
    "                            })\n",
    "                            if title not in relation_types:\n",
    "                                relation_types[title] = set()\n",
    "                            relation_types[title].add(key)\n",
    "    \n",
    "    validation_schema = {entity: list(rels) for entity, rels in relation_types.items()}\n",
    "    \n",
    "    return entities, relations, contents, validation_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d93674",
   "metadata": {},
   "source": [
    "#### Define the entities and relations that will be used by the knwoledge graph extractor\n",
    "\n",
    "The entities and relations are stored in a specific folder called \"ontology\". Think of an ontology as organizing principles for the knowledge that is inside the Obsidian vault. It will be transmitted to the knowledge graph extractor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28927b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_dir = \"**/ontology\"\n",
    "entities, relations, contents, validation_schema = process_obsidian_notes(ontology_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5297996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un knowlege extractor qui va mapper des données non-structurées en suivant le modèle de connaissance\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    max_triplets_per_chunk=20,\n",
    "    strict=False,\n",
    "    num_workers=4,\n",
    "    possible_entities=[entity[\"name\"] for entity in entities],  # Si vous ne limitez pas les types d'entités\n",
    "    possible_relations=[relation[\"type\"] for relation in relations],  # Si vous ne limitez pas les types de relations\n",
    "    kg_validation_schema=validation_schema,\n",
    "    possible_entity_props=[content[\"content\"] for content in contents],\n",
    "    possible_relation_props=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eeaf52",
   "metadata": {},
   "source": [
    "#### Construct property graph store and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceda119",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_store = SimpleGraphStore()\n",
    "pg_storage_context = StorageContext.from_defaults(graph_store=pg_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_graph_index = PropertyGraphIndex.from_documents(\n",
    "    documents=[process_document(doc) for doc in data],\n",
    "    llm=llm,\n",
    "    storage_context=onto_storage_context,\n",
    "    embed_kg_nodes=True,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    show_progress=True,\n",
    "    graph_store=onto_store \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "property_graph_index.set_index_id(\"pg_index\")\n",
    "property_graph_index.storage_context.persist(\"pg_store\")\n",
    "property_graph_index.persist(persist_dir=\"pg_store\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
